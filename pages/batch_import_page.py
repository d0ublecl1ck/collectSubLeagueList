# -*- coding: utf-8 -*-
"""
æ‰¹é‡å¯¼å…¥é¡µé¢ - æä¾› Task æ¨¡å‹çš„æ‰¹é‡æ•°æ®å¯¼å…¥ç•Œé¢ï¼ˆé‡æ–°è®¾è®¡å¸ƒå±€ï¼‰
"""

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import pandas as pd
import os
from datetime import datetime

from .base_page import BasePage
from models import Task, Team, JsDataRaw, Standings


class BatchImportPage(BasePage):
    """æ‰¹é‡å¯¼å…¥é¡µé¢ - ä»»åŠ¡æ‰¹é‡å¯¼å…¥åŠŸèƒ½"""
    
    def setup_scrollable_container(self):
        """è®¾ç½®å¯æ»šåŠ¨çš„å®¹å™¨"""
        # åˆ›å»ºCanvaså’Œæ»šåŠ¨æ¡
        self.canvas = tk.Canvas(self.frame)
        self.v_scrollbar = ttk.Scrollbar(self.frame, orient=tk.VERTICAL, command=self.canvas.yview)
        self.canvas.configure(yscrollcommand=self.v_scrollbar.set)
        
        # åˆ›å»ºå¯æ»šåŠ¨çš„æ¡†æ¶
        self.scrollable_frame = ttk.Frame(self.canvas)
        self.canvas_window = self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")
        
        # å¸ƒå±€Canvaså’Œæ»šåŠ¨æ¡
        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        self.v_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # ç»‘å®šäº‹ä»¶
        self.scrollable_frame.bind('<Configure>', self.on_frame_configure)
        self.canvas.bind('<Configure>', self.on_canvas_configure)
        self.canvas.bind_all('<MouseWheel>', self.on_mousewheel)
    
    def on_frame_configure(self, event):
        """å½“å†…éƒ¨æ¡†æ¶å¤§å°æ”¹å˜æ—¶æ›´æ–°æ»šåŠ¨åŒºåŸŸ"""
        self.canvas.configure(scrollregion=self.canvas.bbox("all"))
    
    def on_canvas_configure(self, event):
        """å½“Canvaså¤§å°æ”¹å˜æ—¶è°ƒæ•´å†…éƒ¨æ¡†æ¶å®½åº¦"""
        canvas_width = event.width
        self.canvas.itemconfig(self.canvas_window, width=canvas_width)
    
    def on_mousewheel(self, event):
        """é¼ æ ‡æ»šè½®äº‹ä»¶"""
        self.canvas.yview_scroll(int(-1*(event.delta/120)), "units")
    
    def setup_ui(self):
        """è®¾ç½®æ‰¹é‡å¯¼å…¥é¡µé¢çš„ç”¨æˆ·ç•Œé¢"""
        # åˆ›å»ºå¯æ»šåŠ¨çš„ä¸»å®¹å™¨
        self.setup_scrollable_container()
        
        # é¡µé¢æ ‡é¢˜
        title_label = ttk.Label(
            self.scrollable_frame, 
            text="æ‰¹é‡å¯¼å…¥", 
            font=('Arial', 16, 'bold')
        )
        title_label.pack(pady=(0, 15))
        
        # æ–‡ä»¶é€‰æ‹©å’Œæ§åˆ¶åŒºåŸŸï¼ˆç½®é¡¶ï¼‰
        self.setup_file_and_import_area()
        
        # æ•°æ®é¢„è§ˆåŒºåŸŸ
        self.setup_preview_area()
        
        # æ ·ä¾‹ä¸‹è½½åŒºåŸŸï¼ˆåº•éƒ¨ï¼Œç´§å‡‘ï¼‰
        self.setup_sample_download_area()
        
        # åˆå§‹åŒ–å˜é‡
        self.current_data = None
        self.validation_results = []
        self.duplicate_results = []
    
    def setup_file_and_import_area(self):
        """è®¾ç½®æ–‡ä»¶é€‰æ‹©å’Œå¯¼å…¥æ§åˆ¶åŒºåŸŸï¼ˆåˆå¹¶é¡¶éƒ¨åŒºåŸŸï¼‰"""
        # ä¸»æ§åˆ¶æ¡†æ¶
        control_frame = ttk.LabelFrame(self.scrollable_frame, text="æ–‡ä»¶å¯¼å…¥", padding=15)
        control_frame.pack(fill=tk.X, pady=(0, 15))
        
        # åˆ›å»ºå·¦å³åˆ†æ 
        main_frame = ttk.Frame(control_frame)
        main_frame.pack(fill=tk.X)
        
        # å·¦ä¾§ï¼šæ–‡ä»¶è·¯å¾„è¾“å…¥
        left_frame = ttk.Frame(main_frame)
        left_frame.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 15))
        
        # æ–‡ä»¶é€‰æ‹©è¡Œ
        file_frame = ttk.Frame(left_frame)
        file_frame.pack(fill=tk.X, pady=(0, 15))
        
        ttk.Label(file_frame, text="æ–‡ä»¶è·¯å¾„:", width=8).pack(side=tk.LEFT, padx=(0, 5))
        
        self.file_path_var = tk.StringVar()
        self.file_path_entry = ttk.Entry(
            file_frame, 
            textvariable=self.file_path_var,
            state='readonly'
        )
        self.file_path_entry.pack(side=tk.LEFT, fill=tk.X, expand=True)
        
        # çŠ¶æ€æ˜¾ç¤ºè¡Œ
        status_frame = ttk.Frame(left_frame)
        status_frame.pack(fill=tk.X)
        
        self.status_label = ttk.Label(
            status_frame, 
            text="è¯·é€‰æ‹©è¦å¯¼å…¥çš„æ–‡ä»¶",
            font=('Arial', 10),
            foreground='blue'
        )
        self.status_label.pack(side=tk.LEFT)
        
        # å³ä¾§ï¼šæŒ‰é’®åˆ—
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(side=tk.RIGHT)
        
        # æµè§ˆæŒ‰é’®
        browse_btn = ttk.Button(
            button_frame,
            text="æµè§ˆæ–‡ä»¶",
            command=self.browse_file,
            width=15
        )
        browse_btn.pack(pady=(0, 8))
        
        # è§£ææŒ‰é’®
        parse_btn = ttk.Button(
            button_frame,
            text="è§£ææ–‡ä»¶",
            command=self.parse_file,
            width=15
        )
        parse_btn.pack(pady=(0, 8))
        
        # å¯¼å…¥æŒ‰é’®ï¼ˆçªå‡ºæ˜¾ç¤ºï¼‰
        self.import_btn = ttk.Button(
            button_frame,
            text="ğŸ“¥ æ‰§è¡Œæ‰¹é‡å¯¼å…¥",
            command=self.execute_import,
            width=15,
            state='disabled'
        )
        self.import_btn.pack()
    
    
    def setup_preview_area(self):
        """è®¾ç½®æ•°æ®é¢„è§ˆåŒºåŸŸ"""
        preview_frame = ttk.LabelFrame(self.scrollable_frame, text="æ•°æ®é¢„è§ˆ", padding=15)
        preview_frame.pack(fill=tk.X, pady=(0, 15))
        
        # åˆ›å»ºTreeviewè¡¨æ ¼
        columns = ['level', 'event', 'country', 'league', 'type', 'year', 'group', 'link', 'link_second']
        column_names = ['çº§åˆ«', 'èµ›äº‹åç§°', 'å›½å®¶/åœ°åŒº', 'è”èµ›åç§°', 'ç±»å‹', 'å¹´ä»½', 'åˆ†ç»„', 'ä¸»é“¾æ¥', 'å¤‡ç”¨é“¾æ¥']
        
        self.preview_tree = ttk.Treeview(preview_frame, columns=columns, show='headings', height=8)
        
        # è®¾ç½®åˆ—æ ‡é¢˜å’Œå®½åº¦
        for col, name in zip(columns, column_names):
            self.preview_tree.heading(col, text=name)
            self.preview_tree.column(col, width=80, minwidth=50)
        
        # æ·»åŠ æ»šåŠ¨æ¡
        v_scrollbar = ttk.Scrollbar(preview_frame, orient=tk.VERTICAL, command=self.preview_tree.yview)
        h_scrollbar = ttk.Scrollbar(preview_frame, orient=tk.HORIZONTAL, command=self.preview_tree.xview)
        
        self.preview_tree.configure(yscrollcommand=v_scrollbar.set, xscrollcommand=h_scrollbar.set)
        
        # å¸ƒå±€
        self.preview_tree.grid(row=0, column=0, sticky='nsew')
        v_scrollbar.grid(row=0, column=1, sticky='ns')
        h_scrollbar.grid(row=1, column=0, sticky='ew')
        
        preview_frame.grid_rowconfigure(0, weight=1)
        preview_frame.grid_columnconfigure(0, weight=1)
        
        # éªŒè¯ç»“æœæ˜¾ç¤ºï¼ˆè‡ªåŠ¨è°ƒæ•´é«˜åº¦ï¼‰
        self.validation_text = tk.Text(preview_frame, height=1, state='disabled', wrap=tk.WORD)
        
        # æ·»åŠ éªŒè¯ç»“æœæ–‡æœ¬æ¡†çš„æ»šåŠ¨æ¡
        validation_scrollbar = ttk.Scrollbar(preview_frame, orient=tk.VERTICAL, command=self.validation_text.yview)
        self.validation_text.configure(yscrollcommand=validation_scrollbar.set)
        
        self.validation_text.grid(row=2, column=0, sticky='ew', pady=(10, 0))
        validation_scrollbar.grid(row=2, column=1, sticky='ns', pady=(10, 0))
    
    def setup_sample_download_area(self):
        """è®¾ç½®æ ·ä¾‹ä¸‹è½½åŒºåŸŸï¼ˆåº•éƒ¨ç´§å‡‘ç‰ˆï¼‰"""
        sample_frame = ttk.LabelFrame(self.scrollable_frame, text="å¯¼å…¥æ ¼å¼è¯´æ˜", padding=10)
        sample_frame.pack(fill=tk.X, pady=(10, 0))
        
        # æ ¼å¼è¯´æ˜
        format_info = ttk.Label(
            sample_frame,
            text="å¿…å¡«å­—æ®µï¼šèµ›äº‹çº§åˆ«*, èµ›äº‹åç§°*, å›½å®¶/åœ°åŒº*, è”èµ›åç§°*, èµ›äº‹ç±»å‹*, èµ›äº‹å¹´ä»½* | æ”¯æŒæ ¼å¼ï¼šExcel(.xlsx), CSV(.csv), TABåˆ†éš”(.txt)",
            font=('Arial', 9),
            foreground='#666666'
        )
        format_info.pack(anchor='w', pady=(0, 10))
        
        # æ ·ä¾‹ä¸‹è½½æŒ‰é’®è¡Œ
        sample_btn_frame = ttk.Frame(sample_frame)
        sample_btn_frame.pack(fill=tk.X)
        
        ttk.Label(sample_btn_frame, text="æ ·ä¾‹ä¸‹è½½:", font=('Arial', 9)).pack(side=tk.LEFT, padx=(0, 10))
        
        # Excelæ ·ä¾‹æŒ‰é’®
        excel_btn = ttk.Button(
            sample_btn_frame,
            text="Excelæ ·ä¾‹",
            command=self.download_excel_sample,
            width=12
        )
        excel_btn.pack(side=tk.LEFT, padx=(0, 8))
        
        # CSVæ ·ä¾‹æŒ‰é’®
        csv_btn = ttk.Button(
            sample_btn_frame,
            text="CSVæ ·ä¾‹",
            command=self.download_csv_sample,
            width=12
        )
        csv_btn.pack(side=tk.LEFT, padx=(0, 8))
        
        # TABæ ·ä¾‹æŒ‰é’®
        tab_btn = ttk.Button(
            sample_btn_frame,
            text="TABæ ·ä¾‹",
            command=self.download_tab_sample,
            width=12
        )
        tab_btn.pack(side=tk.LEFT)
    
    def browse_file(self):
        """æµè§ˆé€‰æ‹©å¯¼å…¥æ–‡ä»¶"""
        file_path = filedialog.askopenfilename(
            title="é€‰æ‹©å¯¼å…¥æ–‡ä»¶",
            filetypes=[
                ("æ”¯æŒçš„æ–‡ä»¶", "*.xlsx;*.xls;*.txt;*.csv"),
                ("Excelæ–‡ä»¶", "*.xlsx;*.xls"),
                ("æ–‡æœ¬æ–‡ä»¶", "*.txt;*.csv"),
                ("æ‰€æœ‰æ–‡ä»¶", "*.*")
            ]
        )
        
        if file_path:
            self.file_path_var.set(file_path)
            self.log_action("é€‰æ‹©æ–‡ä»¶", f"æ–‡ä»¶è·¯å¾„: {file_path}")
    
    def parse_file(self):
        """è§£æå¯¼å…¥æ–‡ä»¶"""
        file_path = self.file_path_var.get()
        if not file_path:
            self.show_message("æç¤º", "è¯·å…ˆé€‰æ‹©è¦å¯¼å…¥çš„æ–‡ä»¶", "warning")
            return
        
        if not os.path.exists(file_path):
            self.show_message("é”™è¯¯", "æ–‡ä»¶ä¸å­˜åœ¨", "error")
            return
        
        try:
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è§£ææ–¹å¼
            file_ext = os.path.splitext(file_path)[1].lower()
            
            if file_ext in ['.xlsx', '.xls']:
                df = pd.read_excel(file_path)
                separator_used = "Excelæ ¼å¼"
            elif file_ext in ['.txt', '.csv']:
                # æ™ºèƒ½æ£€æµ‹åˆ†éš”ç¬¦
                df, separator_used = self.detect_separator_and_parse(file_path)
            else:
                self.show_message("é”™è¯¯", "ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼", "error")
                return
            
            # æ ‡å‡†åŒ–åˆ—å
            df = self.normalize_column_names(df)
            
            # éªŒè¯æ•°æ®
            self.current_data = df
            validation_results = self.validate_data(df)
            
            # æ£€æµ‹é‡å¤æ•°æ®
            duplicate_results = self.detect_duplicates_in_file(df)
            self.duplicate_results = duplicate_results
            
            # æ˜¾ç¤ºé¢„è§ˆ
            self.display_preview(df)
            self.display_validation_results(validation_results, duplicate_results)
            
            # å¯ç”¨å¯¼å…¥æŒ‰é’®
            if all(result['valid'] for result in validation_results):
                self.import_btn.config(state='normal')
                self.status_label.config(
                    text=f"âœ… æ•°æ®éªŒè¯é€šè¿‡ï¼Œå…± {len(df)} æ¡è®°å½• ({separator_used})ï¼Œå¯ä»¥å¯¼å…¥",
                    foreground='green'
                )
            else:
                self.import_btn.config(state='disabled')
                self.status_label.config(
                    text="âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯",
                    foreground='red'
                )
            
            self.log_action("è§£ææ–‡ä»¶", f"æˆåŠŸè§£æ {len(df)} æ¡è®°å½•ï¼Œä½¿ç”¨{separator_used}")
            
        except Exception as e:
            self.logger.error(f"è§£ææ–‡ä»¶å¤±è´¥: {e}")
            self.show_message("é”™è¯¯", f"è§£æå¤±è´¥: {str(e)}", "error")
            self.status_label.config(text="æ–‡ä»¶è§£æå¤±è´¥")

    # ä¿æŒåŸæœ‰çš„å…¶ä»–æ–¹æ³•ä¸å˜
    def download_excel_sample(self):
        """ä¸‹è½½Excelæ ·ä¾‹æ–‡ä»¶"""
        try:
            # åˆ›å»ºæ ·ä¾‹æ•°æ®
            sample_data = {
                'level': [1, 2],
                'event': ['æ¬§æ´²å† å†›è”èµ›', 'è‹±æ ¼å…°è¶³çƒè¶…çº§è”èµ›'],
                'country': ['æ¬§æ´²', 'è‹±æ ¼å…°'],
                'league': ['æ¬§å† ', 'è‹±è¶…'],
                'type': ['å¸¸è§„', 'å¸¸è§„'],
                'year': ['2024', '2024'],
                'group': ['Aç»„', 'é»˜è®¤ç»„'],
                'link': ['https://example.com/ucl', 'https://example.com/epl'],
                'link_second': ['', '']
            }
            
            df = pd.DataFrame(sample_data)
            
            # é€‰æ‹©ä¿å­˜ä½ç½®
            file_path = filedialog.asksaveasfilename(
                title="ä¿å­˜Excelæ ·ä¾‹æ–‡ä»¶",
                defaultextension=".xlsx",
                filetypes=[("Excelæ–‡ä»¶", "*.xlsx")]
            )
            
            if file_path:
                df.to_excel(file_path, index=False)
                self.show_message("æˆåŠŸ", f"Excelæ ·ä¾‹æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{file_path}", "info")
                self.log_action("ä¸‹è½½æ ·ä¾‹", f"Excelæ ·ä¾‹: {file_path}")
                
        except Exception as e:
            self.logger.error(f"ä¸‹è½½Excelæ ·ä¾‹å¤±è´¥: {e}")
            self.show_message("é”™è¯¯", f"ä¸‹è½½å¤±è´¥: {str(e)}", "error")
    
    def download_csv_sample(self):
        """ä¸‹è½½CSVæ ·ä¾‹æ–‡ä»¶"""
        try:
            # CSVæ ·ä¾‹å†…å®¹ï¼ˆé€—å·åˆ†éš”ï¼‰
            sample_content = """level,event,country,league,type,year,group,link,link_second
1,æ¬§æ´²å† å†›è”èµ›,æ¬§æ´²,æ¬§å† ,å¸¸è§„,2024,Aç»„,https://example.com/ucl,
2,è‹±æ ¼å…°è¶³çƒè¶…çº§è”èµ›,è‹±æ ¼å…°,è‹±è¶…,å¸¸è§„,2024,é»˜è®¤ç»„,https://example.com/epl,"""
            
            # é€‰æ‹©ä¿å­˜ä½ç½®
            file_path = filedialog.asksaveasfilename(
                title="ä¿å­˜CSVæ ·ä¾‹æ–‡ä»¶",
                defaultextension=".csv",
                filetypes=[("CSVæ–‡ä»¶", "*.csv"), ("æ–‡æœ¬æ–‡ä»¶", "*.txt")]
            )
            
            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(sample_content)
                self.show_message("æˆåŠŸ", f"CSVæ ·ä¾‹æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{file_path}", "info")
                self.log_action("ä¸‹è½½æ ·ä¾‹", f"CSVæ ·ä¾‹: {file_path}")
                
        except Exception as e:
            self.logger.error(f"ä¸‹è½½CSVæ ·ä¾‹å¤±è´¥: {e}")
            self.show_message("é”™è¯¯", f"ä¸‹è½½å¤±è´¥: {str(e)}", "error")
    
    def download_tab_sample(self):
        """ä¸‹è½½TABåˆ†éš”ç¬¦æ ·ä¾‹æ–‡ä»¶"""
        try:
            # TABæ ·ä¾‹å†…å®¹ï¼ˆåˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰
            sample_content = """level\tevent\tcountry\tleague\ttype\tyear\tgroup\tlink\tlink_second
1\tæ¬§æ´²å† å†›è”èµ›\tæ¬§æ´²\tæ¬§å† \tå¸¸è§„\t2024\tAç»„\thttps://example.com/ucl\t
2\tè‹±æ ¼å…°è¶³çƒè¶…çº§è”èµ›\tè‹±æ ¼å…°\tè‹±è¶…\tå¸¸è§„\t2024\té»˜è®¤ç»„\thttps://example.com/epl\t"""
            
            # é€‰æ‹©ä¿å­˜ä½ç½®
            file_path = filedialog.asksaveasfilename(
                title="ä¿å­˜TABåˆ†éš”ç¬¦æ ·ä¾‹æ–‡ä»¶",
                defaultextension=".txt",
                filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("åˆ¶è¡¨ç¬¦æ–‡ä»¶", "*.tsv")]
            )
            
            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(sample_content)
                self.show_message("æˆåŠŸ", f"TABæ ·ä¾‹æ–‡ä»¶å·²ä¿å­˜åˆ°ï¼š{file_path}", "info")
                self.log_action("ä¸‹è½½æ ·ä¾‹", f"TABæ ·ä¾‹: {file_path}")
                
        except Exception as e:
            self.logger.error(f"ä¸‹è½½TABæ ·ä¾‹å¤±è´¥: {e}")
            self.show_message("é”™è¯¯", f"ä¸‹è½½å¤±è´¥: {str(e)}", "error")
    
    def validate_data(self, df):
        """éªŒè¯å¯¼å…¥æ•°æ®"""
        results = []
        required_fields = ['level', 'event', 'country', 'league', 'type', 'year']
        
        # æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨ï¼ˆå·²ç»è¿‡åˆ—åæ ‡å‡†åŒ–å¤„ç†ï¼‰
        missing_columns = [col for col in required_fields if col not in df.columns]
        if missing_columns:
            results.append({
                'valid': False,
                'message': f"ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing_columns)}"
            })
            return results
        
        # é€è¡ŒéªŒè¯æ•°æ®
        for index, row in df.iterrows():
            row_errors = []
            
            # æ£€æŸ¥å¿…å¡«å­—æ®µ
            for field in required_fields:
                if pd.isna(row[field]) or str(row[field]).strip() == '':
                    row_errors.append(f"{field}ä¸ºç©º")
            
            # éªŒè¯çº§åˆ«ä¸ºæ•°å­—
            try:
                if not pd.isna(row['level']):
                    int(row['level'])
            except (ValueError, TypeError):
                row_errors.append("levelå¿…é¡»ä¸ºæ•°å­—")
            
            # éªŒè¯ç±»å‹æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…
            valid_types = ["å¸¸è§„", "è”äºŒåˆå¹¶", "æ˜¥ç§‹åˆå¹¶", "ä¸œè¥¿æ‹†åˆ†"]
            if not pd.isna(row['type']) and str(row['type']) not in valid_types:
                row_errors.append(f"typeå¿…é¡»ä¸º: {', '.join(valid_types)}")
            
            # è®°å½•éªŒè¯ç»“æœ
            if row_errors:
                results.append({
                    'valid': False,
                    'row': index + 1,
                    'message': f"ç¬¬{index + 1}è¡Œé”™è¯¯: {'; '.join(row_errors)}"
                })
            else:
                results.append({
                    'valid': True,
                    'row': index + 1,
                    'message': f"ç¬¬{index + 1}è¡ŒéªŒè¯é€šè¿‡"
                })
        
        return results
    
    def display_preview(self, df):
        """æ˜¾ç¤ºæ•°æ®é¢„è§ˆ"""
        # æ¸…ç©ºç°æœ‰æ•°æ®
        for item in self.preview_tree.get_children():
            self.preview_tree.delete(item)
        
        # æ’å…¥æ•°æ®è¡Œï¼ˆæœ€å¤šæ˜¾ç¤ºå‰50è¡Œï¼‰
        display_rows = min(50, len(df))
        for index in range(display_rows):
            row = df.iloc[index]
            values = []
            for col in self.preview_tree['columns']:
                if col in df.columns:
                    val = row[col]
                    if pd.isna(val):
                        values.append('')
                    else:
                        values.append(str(val))
                else:
                    values.append('')
            
            self.preview_tree.insert('', 'end', values=values)
        
        if len(df) > 50:
            # æ·»åŠ æç¤ºä¿¡æ¯
            note_values = ['...', f'å…±{len(df)}æ¡è®°å½•', 'ä»…æ˜¾ç¤ºå‰50æ¡', '...', '...', '...', '...', '...', '...']
            self.preview_tree.insert('', 'end', values=note_values)
    
    def display_validation_results(self, results, duplicate_results=None):
        """æ˜¾ç¤ºéªŒè¯ç»“æœå’Œé‡å¤æ£€æµ‹ç»“æœ"""
        self.validation_text.config(state='normal')
        self.validation_text.delete(1.0, tk.END)
        
        # ç»Ÿè®¡
        total_rows = len(results)
        valid_rows = len([r for r in results if r['valid']])
        invalid_rows = total_rows - valid_rows
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        summary = f"éªŒè¯ç»“æœ: æ€»è®¡ {total_rows} è¡Œï¼Œé€šè¿‡ {valid_rows} è¡Œï¼Œå¤±è´¥ {invalid_rows} è¡Œ\n"
        self.validation_text.insert(tk.END, summary)
        
        # æ˜¾ç¤ºé‡å¤æ£€æµ‹ç»“æœ
        if duplicate_results:
            total_duplicate_rows = sum(dup['count'] for dup in duplicate_results)
            unique_combinations = len(duplicate_results)
            
            self.validation_text.insert(tk.END, f"\nâš ï¸ å‘ç°æ–‡ä»¶å†…é‡å¤æ•°æ®:\n")
            self.validation_text.insert(tk.END, f"é‡å¤ç»„åˆ: {unique_combinations} ç»„ï¼Œå½±å“ {total_duplicate_rows} æ¡è®°å½•\n\n")
            
            # æ˜¾ç¤ºå‰10ç»„é‡å¤è¯¦æƒ…
            displayed_count = 0
            for dup in duplicate_results[:10]:
                displayed_count += 1
                row_nums_str = ', '.join(map(str, dup['row_numbers']))
                self.validation_text.insert(tk.END, 
                    f"ç¬¬{displayed_count}ç»„: {dup['league']}-{dup['year']}-{dup['group']} (è¡Œå·: {row_nums_str})\n")
            
            if len(duplicate_results) > 10:
                self.validation_text.insert(tk.END, f"... è¿˜æœ‰ {len(duplicate_results) - 10} ç»„é‡å¤æœªæ˜¾ç¤º\n")
            
            self.validation_text.insert(tk.END, "\nğŸ“ å¯¼å…¥æ—¶å°†ä¿ç•™æ¯ç»„çš„æœ€åä¸€æ¡è®°å½•ï¼Œå‰é¢çš„è®°å½•ä¼šè¢«è¦†ç›–ã€‚\n\n")
        else:
            self.validation_text.insert(tk.END, "\nâœ… æœªå‘ç°æ–‡ä»¶å†…é‡å¤æ•°æ®\n\n")
        
        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        if invalid_rows > 0:
            self.validation_text.insert(tk.END, "éªŒè¯é”™è¯¯è¯¦æƒ…:\n")
            error_results = [r for r in results if not r['valid']]
            for result in error_results:
                self.validation_text.insert(tk.END, result['message'] + '\n')
            
            if len(error_results) < invalid_rows:
                self.validation_text.insert(tk.END, f"... è¿˜æœ‰ {invalid_rows - len(error_results)} ä¸ªé”™è¯¯æœªæ˜¾ç¤º\n")
        
        self.validation_text.config(state='disabled')
        self.validation_results = results
        
        # è‡ªåŠ¨è°ƒæ•´æ–‡æœ¬æ¡†é«˜åº¦
        self.auto_resize_validation_text()
    
    def auto_resize_validation_text(self):
        """è‡ªåŠ¨è°ƒæ•´éªŒè¯ç»“æœæ–‡æœ¬æ¡†çš„é«˜åº¦"""
        # è·å–æ–‡æœ¬å†…å®¹çš„è¡Œæ•°
        content = self.validation_text.get(1.0, tk.END)
        line_count = content.count('\n')
        
        # è®¾ç½®æœ€å°å’Œæœ€å¤§é«˜åº¦
        min_height = 3
        max_height = 15
        
        # æ ¹æ®å†…å®¹è°ƒæ•´é«˜åº¦ï¼Œä½†é™åˆ¶åœ¨æœ€å°å’Œæœ€å¤§å€¼ä¹‹é—´
        new_height = max(min_height, min(line_count + 1, max_height))
        
        # æ›´æ–°æ–‡æœ¬æ¡†é«˜åº¦
        self.validation_text.config(height=new_height)
        
        # æ›´æ–°æ»šåŠ¨åŒºåŸŸï¼ˆå¦‚æœå†…å®¹éœ€è¦æ»šåŠ¨çš„è¯ï¼‰
        if hasattr(self, 'canvas'):
            self.canvas.configure(scrollregion=self.canvas.bbox("all"))
    
    def has_core_field_changes(self, existing_task, new_data):
        """æ£€æµ‹æ˜¯å¦æœ‰æ ¸å¿ƒå­—æ®µå˜æ›´"""
        core_fields = ['level', 'event', 'country', 'league', 'type', 'year', 'group', 'link', 'link_second']
        changes = []
        
        for field in core_fields:
            # è·å–æ–°å€¼
            if field == 'level':
                new_value = int(new_data['level'])
            elif field in ['link', 'link_second']:
                new_value = str(new_data.get(field, '')) if not pd.isna(new_data.get(field)) else None
                # å¤„ç†ç©ºå­—ç¬¦ä¸²
                if new_value == '':
                    new_value = None
            else:
                new_value = str(new_data[field]) if not pd.isna(new_data[field]) else None
            
            # è·å–ç°æœ‰å€¼
            existing_value = getattr(existing_task, field)
            
            # æ¯”è¾ƒå€¼
            if existing_value != new_value:
                changes.append(f"{field}: '{existing_value}' -> '{new_value}'")
        
        return len(changes) > 0, changes
    
    def clear_related_data(self, session, task_id):
        """æ¸…ç©ºæŒ‡å®šä»»åŠ¡çš„å…³è”æ•°æ®"""
        try:
            # åˆ é™¤ teams æ•°æ®
            session.query(Team).filter_by(task_id=task_id).delete()
            # åˆ é™¤ js_data_raw æ•°æ®
            session.query(JsDataRaw).filter_by(task_id=task_id).delete()
            # åˆ é™¤ standings æ•°æ®
            session.query(Standings).filter_by(task_id=task_id).delete()
            
            self.logger.info(f"å·²æ¸…ç©ºä»»åŠ¡ {task_id} çš„å…³è”æ•°æ®")
        except Exception as e:
            self.logger.error(f"æ¸…ç©ºä»»åŠ¡ {task_id} å…³è”æ•°æ®å¤±è´¥: {e}")
            raise
    
    def update_task_fields(self, existing_task, new_data, group):
        """æ›´æ–°ä»»åŠ¡å­—æ®µ"""
        existing_task.level = int(new_data['level'])
        existing_task.event = str(new_data['event'])
        existing_task.country = str(new_data['country'])
        existing_task.league = str(new_data['league'])
        existing_task.type = str(new_data['type'])
        existing_task.year = str(new_data['year'])
        existing_task.group = str(group)
        
        # å¤„ç† link å­—æ®µ
        link_value = str(new_data.get('link', '')) if not pd.isna(new_data.get('link')) else None
        existing_task.link = link_value if link_value != '' else None
        
        # å¤„ç† link_second å­—æ®µ
        link_second_value = str(new_data.get('link_second', '')) if not pd.isna(new_data.get('link_second')) else None
        existing_task.link_second = link_second_value if link_second_value != '' else None
        
        # updated_at ä¼šè‡ªåŠ¨æ›´æ–°

    def execute_import(self):
        """æ‰§è¡Œæ‰¹é‡å¯¼å…¥ï¼ˆæ”¯æŒæ›´æ–°æ¨¡å¼ï¼‰"""
        if self.current_data is None:
            self.show_message("æç¤º", "è¯·å…ˆé€‰æ‹©å¹¶è§£ææ–‡ä»¶", "warning")
            return
        
        # å†æ¬¡éªŒè¯
        if not all(result['valid'] for result in self.validation_results):
            self.show_message("é”™è¯¯", "æ•°æ®éªŒè¯å¤±è´¥ï¼Œæ— æ³•å¯¼å…¥", "error")
            return
        
        try:
            insert_count = 0  # æ–°å¢è®°å½•æ•°
            major_update_count = 0  # é‡è¦æ›´æ–°æ•°ï¼ˆæ¸…ç©ºå…³è”æ•°æ®ï¼‰
            minor_update_count = 0  # ä¸€èˆ¬æ›´æ–°æ•°ï¼ˆä»…æ›´æ–°å­—æ®µï¼‰
            error_count = 0
            
            # è®¡ç®—æ–‡ä»¶å†…é‡å¤ç»Ÿè®¡
            file_duplicate_count = 0
            if self.duplicate_results:
                file_duplicate_count = sum(dup['count'] for dup in self.duplicate_results) - len(self.duplicate_results)
                # å‡å»æ¯ç»„ä¿ç•™çš„æœ€åä¸€æ¡ï¼Œå‰©ä¸‹çš„å°±æ˜¯è¢«è¦†ç›–çš„æ•°é‡
            
            with self.get_db_session() as session:
                for index, row in self.current_data.iterrows():
                    try:
                        # å¤„ç† group å­—æ®µé»˜è®¤å€¼
                        group = row.get('group', 'é»˜è®¤ç»„')
                        if pd.isna(group) or str(group).strip() == '':
                            group = 'é»˜è®¤ç»„'
                        
                        # æŸ¥æ‰¾ç°æœ‰è®°å½•
                        existing_task = session.query(Task).filter_by(
                            league=str(row['league']),
                            year=str(row['year']),
                            group=str(group)
                        ).first()
                        
                        if existing_task:
                            # æ£€æŸ¥æ˜¯å¦æœ‰æ ¸å¿ƒå­—æ®µå˜æ›´
                            has_changes, change_details = self.has_core_field_changes(existing_task, row)
                            
                            if has_changes:
                                # æ¸…ç©ºå…³è”æ•°æ®
                                self.clear_related_data(session, existing_task.id)
                                # æ›´æ–°ä»»åŠ¡å­—æ®µ
                                self.update_task_fields(existing_task, row, group)
                                major_update_count += 1
                                self.logger.info(f"ç¬¬{index + 1}è¡Œé‡è¦æ›´æ–°: {row['league']}-{row['year']}-{group}, å˜æ›´: {'; '.join(change_details)}")
                            else:
                                # åªæ˜¯ä¸€èˆ¬æ›´æ–°
                                self.update_task_fields(existing_task, row, group)
                                minor_update_count += 1
                                self.logger.debug(f"ç¬¬{index + 1}è¡Œä¸€èˆ¬æ›´æ–°: {row['league']}-{row['year']}-{group}")
                        else:
                            # åˆ›å»ºæ–°ä»»åŠ¡
                            new_task = Task(
                                level=int(row['level']),
                                event=str(row['event']),
                                country=str(row['country']),
                                league=str(row['league']),
                                type=str(row['type']),
                                year=str(row['year']),
                                group=str(group),
                                link=str(row.get('link', '')) if not pd.isna(row.get('link')) and str(row.get('link', '')) != '' else None,
                                link_second=str(row.get('link_second', '')) if not pd.isna(row.get('link_second')) and str(row.get('link_second', '')) != '' else None
                            )
                            session.add(new_task)
                            insert_count += 1
                            self.logger.info(f"ç¬¬{index + 1}è¡Œæ–°å¢: {row['league']}-{row['year']}-{group}")
                        
                    except Exception as e:
                        error_count += 1
                        self.logger.error(f"ç¬¬{index + 1}è¡Œå¤„ç†å¤±è´¥: {e}")
                
                # æäº¤äº‹åŠ¡
                session.commit()
            
            # æ˜¾ç¤ºå¯¼å…¥ç»“æœ
            result_parts = [f"æ–°å¢: {insert_count}æ¡", f"é‡è¦æ›´æ–°: {major_update_count}æ¡", f"ä¸€èˆ¬æ›´æ–°: {minor_update_count}æ¡"]
            if file_duplicate_count > 0:
                result_parts.append(f"æ–‡ä»¶å†…é‡å¤: {file_duplicate_count}æ¡")
            if error_count > 0:
                result_parts.append(f"é”™è¯¯: {error_count}æ¡")
            
            result_msg = "å¯¼å…¥å®Œæˆï¼" + ", ".join(result_parts)
            self.show_message("å¯¼å…¥ç»“æœ", result_msg, "info" if error_count == 0 else "warning")
            self.status_label.config(text=result_msg, foreground='green')
            
            # è®°å½•æ—¥å¿—
            log_parts = [f"æ–°å¢{insert_count}æ¡", f"é‡è¦æ›´æ–°{major_update_count}æ¡", f"ä¸€èˆ¬æ›´æ–°{minor_update_count}æ¡"]
            if file_duplicate_count > 0:
                log_parts.append(f"æ–‡ä»¶å†…é‡å¤{file_duplicate_count}æ¡")
            if error_count > 0:
                log_parts.append(f"é”™è¯¯{error_count}æ¡")
            
            self.log_action("æ‰¹é‡å¯¼å…¥", "ï¼Œ".join(log_parts))
            
            # æ¸…ç©ºæ•°æ®
            if insert_count > 0 or major_update_count > 0 or minor_update_count > 0:
                self.clear_import_data()
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡å¯¼å…¥å¤±è´¥: {e}")
            self.show_message("é”™è¯¯", f"å¯¼å…¥å¤±è´¥: {str(e)}", "error")
    
    def clear_import_data(self):
        """æ¸…ç©ºå¯¼å…¥æ•°æ®"""
        self.file_path_var.set("")
        self.current_data = None
        self.validation_results = []
        self.duplicate_results = []
        
        # æ¸…ç©ºé¢„è§ˆ
        for item in self.preview_tree.get_children():
            self.preview_tree.delete(item)
        
        # æ¸…ç©ºéªŒè¯ç»“æœ
        self.validation_text.config(state='normal')
        self.validation_text.delete(1.0, tk.END)
        self.validation_text.config(state='disabled')
        
        # ç¦ç”¨å¯¼å…¥æŒ‰é’®
        self.import_btn.config(state='disabled')
        self.status_label.config(text="è¯·é€‰æ‹©è¦å¯¼å…¥çš„æ–‡ä»¶", foreground='blue')
        
        self.log_action("æ¸…ç©ºå¯¼å…¥æ•°æ®")
    
    def detect_separator_and_parse(self, file_path):
        """æ™ºèƒ½æ£€æµ‹åˆ†éš”ç¬¦å¹¶è§£ææ–‡ä»¶"""
        # è¯»å–æ–‡ä»¶å‰ä¸¤è¡Œæ¥åˆ¤æ–­æ ¼å¼
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        if len(lines) < 2:
            raise ValueError("æ–‡ä»¶å†…å®¹ä¸è¶³ï¼Œè‡³å°‘éœ€è¦æ ‡é¢˜è¡Œå’Œä¸€è¡Œæ•°æ®")
        
        header_line = lines[0].strip()
        data_line = lines[1].strip()
        
        try:
            # ä½¿ç”¨ split() è‡ªåŠ¨åˆ†å‰²æ ‡é¢˜è¡Œå’Œæ•°æ®è¡Œ
            header_parts = header_line.split()
            data_parts = data_line.split()
            
            # æ£€æŸ¥åˆ—æ•°æ˜¯å¦ä¸€è‡´
            if len(header_parts) != len(data_parts):
                raise ValueError(f"æ ‡é¢˜è¡Œåˆ—æ•°({len(header_parts)})ä¸æ•°æ®è¡Œåˆ—æ•°({len(data_parts)})ä¸ä¸€è‡´")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„åˆ—
            if len(data_parts) < 6:  # è‡³å°‘éœ€è¦6åˆ—å¿…å¡«å­—æ®µ
                raise ValueError("æ•°æ®åˆ—æ•°ä¸è¶³ï¼Œè‡³å°‘éœ€è¦6åˆ—")
            
            # æ ¹æ®æ ‡é¢˜è¡Œç¡®å®štypeå­—æ®µçš„ä½ç½®
            type_index = -1
            for i, col_name in enumerate(header_parts):
                if col_name.lower() == 'type':
                    type_index = i
                    break
            
            if type_index == -1:
                raise ValueError("æœªæ‰¾åˆ°typeåˆ—")
            
            # éªŒè¯typeå­—æ®µå€¼
            type_field = data_parts[type_index].strip()
            valid_types = ["å¸¸è§„", "è”äºŒåˆå¹¶", "æ˜¥ç§‹åˆå¹¶", "ä¸œè¥¿æ‹†åˆ†"]
            if type_field not in valid_types:
                raise ValueError(f"typeå­—æ®µå€¼æ— æ•ˆ: {type_field}")
            
            # æ ¹æ®åˆ—æ•°åˆ¤æ–­æ˜¯å¦åŒ…å«link_secondå­—æ®µ
            if len(data_parts) not in [8, 9]:
                raise ValueError(f"åˆ—æ•°é”™è¯¯ï¼Œåº”ä¸º8æˆ–9åˆ—ï¼Œå®é™…ä¸º{len(data_parts)}åˆ—")
            
            # ä½¿ç”¨ç©ºç™½å­—ç¬¦ä½œä¸ºåˆ†éš”ç¬¦è§£ææ–‡ä»¶
            df = pd.read_csv(file_path, sep='\s+', encoding='utf-8')
            separator_used = "ç©ºç™½åˆ†éš”ç¬¦"
            
            # è®°å½•å®é™…çš„åˆ—é¡ºåº
            self.logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶æ ¼å¼ï¼š{separator_used}")
            self.logger.info(f"åˆ—é¡ºåºï¼š{list(df.columns)}")
            self.logger.info(f"æ•°æ®ï¼šåˆ—æ•°={len(df.columns)}ï¼Œè¡Œæ•°={len(df)}")
            
            return df, separator_used
            
        except Exception as e:
            self.logger.error(f"è§£ææ–‡ä»¶å¤±è´¥ï¼š{e}")
            raise ValueError(f"æ— æ³•è§£ææ–‡ä»¶æ ¼å¼: {str(e)}")
    
    def normalize_column_names(self, df):
        """æ ‡å‡†åŒ–åˆ—åï¼Œæ”¯æŒå¤šç§åˆ—åå˜ä½“"""
        column_mapping = {
            # æ ‡å‡†åˆ—åï¼šå¯èƒ½çš„å˜ä½“åˆ—å
            'level': ['level', 'çº§åˆ«', 'èµ›äº‹çº§åˆ«', 'Level'],
            'event': ['event', 'èµ›äº‹åç§°', 'èµ›äº‹', 'Event'],
            'country': ['country', 'å›½å®¶', 'åœ°åŒº', 'å›½å®¶/åœ°åŒº', 'Country'],
            'league': ['league', 'è”èµ›', 'è”èµ›åç§°', 'League'],
            'type': ['type', 'ç±»å‹', 'èµ›äº‹ç±»å‹', 'Type'],
            'year': ['year', 'å¹´ä»½', 'èµ›äº‹å¹´ä»½', 'Year'],
            'group': ['group', 'åˆ†ç»„', 'ç»„åˆ«', 'åˆ†ç»„ä¿¡æ¯', 'Group'],
            'link': ['link', 'é“¾æ¥', 'ä¸»é“¾æ¥', 'ä¸»è¦é“¾æ¥', 'Link'],
            'link_second': ['link_second', 'å¤‡ç”¨é“¾æ¥', 'ç¬¬äºŒé“¾æ¥', 'æ¬¡è¦é“¾æ¥', 'Link_Second', 'link2']
        }
        
        # åˆ›å»ºé‡å‘½åå­—å…¸
        rename_dict = {}
        df_columns_lower = {col: col.lower().strip() for col in df.columns}
        
        for standard_name, variants in column_mapping.items():
            for variant in variants:
                for original_col, lower_col in df_columns_lower.items():
                    if lower_col == variant.lower():
                        rename_dict[original_col] = standard_name
                        break
                if standard_name in rename_dict.values():
                    break
        
        # é‡å‘½ååˆ—
        df_renamed = df.rename(columns=rename_dict)
        
        # è®°å½•åˆ—åæ˜ å°„
        if rename_dict:
            mapping_info = ", ".join([f"{old}->{new}" for old, new in rename_dict.items()])
            self.logger.info(f"åˆ—åæ˜ å°„ï¼š{mapping_info}")
        
        return df_renamed
    
    def detect_duplicates_in_file(self, df):
        """æ£€æµ‹æ–‡ä»¶å†…é‡å¤æ•°æ®"""
        duplicates = []
        
        # æ ‡å‡†åŒ–å¤„ç†æ•°æ®ï¼ˆæ¨¡æ‹Ÿå¯¼å…¥æ—¶çš„é€»è¾‘ï¼‰
        df_processed = df.copy()
        
        # å¤„ç† group å­—æ®µé»˜è®¤å€¼
        df_processed['group_processed'] = df_processed.apply(
            lambda row: 'é»˜è®¤ç»„' if (pd.isna(row.get('group')) or str(row.get('group', '')).strip() == '') 
                        else str(row.get('group')), axis=1
        )
        
        # åˆ›å»ºå”¯ä¸€é”®
        df_processed['unique_key'] = (
            df_processed['league'].astype(str) + '-' + 
            df_processed['year'].astype(str) + '-' + 
            df_processed['group_processed'].astype(str)
        )
        
        # æŸ¥æ‰¾é‡å¤é¡¹
        duplicate_keys = df_processed['unique_key'].duplicated(keep=False)
        
        if duplicate_keys.any():
            # æŒ‰å”¯ä¸€é”®åˆ†ç»„ï¼Œæ‰¾å‡ºé‡å¤ç»„åˆ
            grouped = df_processed[duplicate_keys].groupby('unique_key')
            
            for unique_key, group in grouped:
                if len(group) > 1:
                    # è§£æå”¯ä¸€é”®
                    key_parts = unique_key.split('-')
                    if len(key_parts) >= 3:
                        league = key_parts[0]
                        year = '-'.join(key_parts[1:-1])  # å¤„ç†å¹´ä»½ä¸­å¯èƒ½åŒ…å«çš„'-'
                        group_name = key_parts[-1]
                        
                        # è®°å½•é‡å¤ä¿¡æ¯
                        row_numbers = [idx + 1 for idx in group.index]  # è½¬æ¢ä¸º1åŸºç´¢å¼•
                        duplicates.append({
                            'league': league,
                            'year': year, 
                            'group': group_name,
                            'unique_key': unique_key,
                            'row_numbers': row_numbers,
                            'count': len(row_numbers),
                            'rows_data': group[['league', 'year', 'group_processed', 'event', 'country']].to_dict('records')
                        })
        
        return duplicates